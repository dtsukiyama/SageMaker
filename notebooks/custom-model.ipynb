{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and deploying a custom estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we upload our data to S3\n",
    "\n",
    "When we processed the data for the canned estimator we saved three datasets, with the prefix 'post,' to the data directory. The will be uploaded to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data', key_prefix='data/post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow addresses the use of custom estimators [here](https://www.tensorflow.org/get_started/custom_estimators).\n",
    "\n",
    "A ```model_fn``` function implements model training, evaluation, and prediction. SageMaker's [repo](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_abalone_age_predictor_using_keras/tensorflow_abalone_age_predictor_using_keras.ipynb) has a in depth explanation of how these are constructed.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "def model_fn(features, labels, mode, params):\n",
    "   # Logic to do the following:\n",
    "   # 1. Configure the model via TensorFlow or Keras operations\n",
    "   # 2. Define the loss function for training/evaluation\n",
    "   # 3. Define the training operation/optimizer\n",
    "   # 4. Generate predictions\n",
    "   # 5. Return predictions/loss/train_op/eval_metric_ops in EstimatorSpec object\n",
    "   return EstimatorSpec(mode, predictions, loss, train_op, eval_metric_ops)\n",
    "   ```\n",
    "\n",
    "If you are somewhat familiar with machine learning and deep learning, configuring the model, defining loss, and the optimizer may be familiar to you. A few issues to pay attention to:\n",
    "\n",
    "* Make sure you are passing the correct outputs to your loss function. So predicted class for classification problems. For regression problems you will pass your output through a linear activation and reshape it:\n",
    "\n",
    "```python\n",
    "\n",
    "  # Connect the output layer to second hidden layer (no activation fn)\n",
    "  output_layer = Dense(1, activation='linear')(second_hidden_layer)\n",
    "\n",
    "  # Reshape output layer to 1-dim Tensor to return predictions\n",
    "  predictions = tf.reshape(output_layer, [-1])\n",
    "  \n",
    "```\n",
    "\n",
    "* Make sure to create a predictions dictionary with the output you want when serving predictions from your endpoint.\n",
    "\n",
    "\n",
    "* Make sure to set the feature size in ```python def serving_input_fn(params)```. When we processed our data we tokenized the text, created a bag of words matrix, but we set the maximum number of words argument to 500. Make sure the inputs match this dimension.\n",
    "\n",
    "```python\n",
    "\n",
    "    inputs = {INPUT_TENSOR_NAME: tf.placeholder(tf.float32, [None, 500])}\n",
    "```\n",
    "\n",
    "* Make sure to set the correct datatypes in the input function ```python def _input_fn(training_dir, training_filename)```. You can see that the label and features have distinct datatypes:\n",
    "\n",
    "```python filename=os.path.join(training_dir, training_filename), target_dtype=np.int, features_dtype=np.float32)```\n",
    "\n",
    "* Make sure that your target label you are training on is set as a categorical encoding, which means do not use one-hot encoding. This is true for the canned TensorFlow estimators and custom estimators that perform classification. I was able to build and train custom Keras estimators locally with one-hot encoding, but this would always fail when submitting training to SagerMaker's infrastructure.\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "### Full estimator:\n",
    "\n",
    "***\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.export.export import build_raw_serving_input_receiver_fn\n",
    "from tensorflow.python.estimator.export.export_output import PredictOutput\n",
    "\n",
    "\n",
    "INPUT_TENSOR_NAME = \"inputs\"\n",
    "SIGNATURE_NAME = \"serving_default\"\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    \n",
    "    # 1. Configure the neural net, in this case a very simple two layer network.\n",
    "    first_hidden_layer = tf.keras.layers.Dense(128, activation='relu', name='first-layer')(features[INPUT_TENSOR_NAME])\n",
    "    second_hidden_layer = tf.keras.layers.Dense(256, activation='relu')(first_hidden_layer)\n",
    "    logits = tf.keras.layers.Dense(20)(second_hidden_layer)\n",
    "\n",
    "    # 1a. This is a classification example we need to find our class predicitons. \n",
    "    predicted_classes = tf.argmax(logits, axis=1)\n",
    "\n",
    "    # Provide an estimator spec for `ModeKeys.PREDICT`.\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions = {\n",
    "            'class_ids': predicted_classes[:, tf.newaxis],\n",
    "            'probabilities': tf.nn.softmax(logits),\n",
    "            'logits': logits,},\n",
    "            export_outputs={SIGNATURE_NAME: PredictOutput({\"jobs\": predicted_classes})})\n",
    "\n",
    "    # 2. Define the loss function for training/evaluation using Tensorflow.\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(tf.cast(labels, dtype=tf.int32), logits)\n",
    "\n",
    "    # 3. Define the training operation/optimizer using Tensorflow operation/optimizer.\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        optimizer=\"Adam\")\n",
    "\n",
    "    # 4. Generate predictions as Tensorflow tensors.\n",
    "    predictions_dict = {\"jobs\": predicted_classes,\n",
    "                        \"classes\": logits}\n",
    "\n",
    "    # 5. Generate necessary evaluation metrics.\n",
    "    # Calculate accuracy\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels, predicted_classes)\n",
    "    }\n",
    "\n",
    "    # Provide an estimator spec for `ModeKeys.EVAL` and `ModeKeys.TRAIN` modes.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops)\n",
    "    \n",
    "\n",
    "def serving_input_fn(params):\n",
    "    inputs = {INPUT_TENSOR_NAME: tf.placeholder(tf.float32, [None, 500])}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "\n",
    "params = {\"learning_rate\": LEARNING_RATE}\n",
    "\n",
    "\n",
    "def train_input_fn(training_dir, params):\n",
    "    return _input_fn(training_dir, 'post_train.csv')\n",
    "\n",
    "\n",
    "def eval_input_fn(training_dir, params):\n",
    "    return _input_fn(training_dir, 'post_test.csv')\n",
    "\n",
    "def _input_fn(training_dir, training_filename):\n",
    "    training_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "        filename=os.path.join(training_dir, training_filename), target_dtype=np.int, features_dtype=np.float32)\n",
    "\n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={INPUT_TENSOR_NAME: np.array(training_set.data)},\n",
    "        y=np.array(training_set.target),\n",
    "        num_epochs=None,\n",
    "        shuffle=True)()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit model for training on SageMaker's infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-tensorflow-py2-cpu-2018-02-13-15-09-28-445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................\n",
      "\u001b[31mexecuting startup script (first run)\u001b[0m\n",
      "\u001b[31m2018-02-13 15:14:41,613 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-02-13 15:14:41,613 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-02-13 15:14:43,307 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-02-13 15:14:44,246 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-02-13 15:14:44,321 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.us-east-2.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-02-13 15:14:44,418 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:{\"environment\": \"cloud\", \"cluster\": {\"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:---------------------------------------------------------\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:going to training\u001b[0m\n",
      "\u001b[31m2018-02-13 15:14:44,496 INFO - root - creating RunConfig:\u001b[0m\n",
      "\u001b[31m2018-02-13 15:14:44,497 INFO - root - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[31m2018-02-13 15:14:44,497 INFO - root - creating the estimator\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Using config: {'_model_dir': u's3://sagemaker-us-east-2-780175542751/sagemaker-tensorflow-py2-cpu-2018-02-13-15-09-28-445/checkpoints', '_save_checkpoints_secs': 300, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': None, '_task_type': u'master', '_environment': u'cloud', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5e0c7bae90>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31m, '_num_worker_replicas': 1, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_log_step_count_steps': 100}\u001b[0m\n",
      "\u001b[31m2018-02-13 15:14:44,498 INFO - root - creating Experiment:\u001b[0m\n",
      "\u001b[31m2018-02-13 15:14:44,498 INFO - root - {'min_eval_frequency': 1000}\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mMonitors are deprecated. Please use tf.train.SessionRunHook.\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /opt/ml/code/custom_estimator.py:38: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mPlease switch to tf.train.get_global_step\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[31m2018-02-13 15:14:48.038280: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving checkpoints for 1 into s3://sagemaker-us-east-2-780175542751/sagemaker-tensorflow-py2-cpu-2018-02-13-15-09-28-445/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 3.0297728, step = 1\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 192.793\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 1.0228013, step = 101 (0.519 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 181.561\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.6689372, step = 201 (0.551 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 188.811\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.96648026, step = 301 (0.530 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 193.375\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.59265924, step = 401 (0.517 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 191.11\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.8294628, step = 501 (0.523 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 202.694\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.73307544, step = 601 (0.493 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 188.315\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.5693087, step = 701 (0.531 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 192.558\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.4798794, step = 801 (0.519 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 200.974\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.4247967, step = 901 (0.498 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Starting evaluation at 2018-02-13-15:14:56\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Restoring parameters from s3://sagemaker-us-east-2-780175542751/sagemaker-tensorflow-py2-cpu-2018-02-13-15-09-28-445/checkpoints/model.ckpt-1\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [1/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [2/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [3/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [4/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [5/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [6/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [7/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [8/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [9/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [10/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [11/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [12/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [13/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [14/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [15/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [16/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [17/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [18/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [19/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [20/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [21/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [22/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [23/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [24/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [25/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [26/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [27/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [28/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [29/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [30/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [31/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [32/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [33/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [34/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [35/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [36/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [37/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [38/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [39/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [40/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [41/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [42/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [43/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [44/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [45/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [46/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [47/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [48/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [49/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [50/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [51/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [52/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [53/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [54/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [55/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [56/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [57/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [58/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [59/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [60/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [61/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [62/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [63/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [64/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [65/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [66/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [67/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [68/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [69/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [70/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [71/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [72/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [73/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [74/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [75/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [76/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [77/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [78/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [79/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [80/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [81/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [82/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [83/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [84/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [85/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [86/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [87/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [88/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [89/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [90/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [91/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [92/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [93/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [94/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [95/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [96/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [97/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [98/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [99/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [100/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Finished evaluation at 2018-02-13-15:15:00\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving dict for global step 1: accuracy = 0.0515625, global_step = 1, loss = 3.0086129\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Validation (step 1000): loss = 3.0086129, global_step = 1, accuracy = 0.0515625\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving checkpoints for 1000 into s3://sagemaker-us-east-2-780175542751/sagemaker-tensorflow-py2-cpu-2018-02-13-15-09-28-445/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Loss for final step: 0.46634322.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Starting evaluation at 2018-02-13-15:15:03\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Restoring parameters from s3://sagemaker-us-east-2-780175542751/sagemaker-tensorflow-py2-cpu-2018-02-13-15-09-28-445/checkpoints/model.ckpt-1000\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [1/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [2/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [3/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [4/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [5/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [6/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [7/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [8/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [9/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [10/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [11/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [12/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [13/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [14/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [15/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [16/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [17/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [18/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [19/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [20/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [21/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [22/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [23/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [24/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [25/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [26/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [27/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [28/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [29/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [30/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [31/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [32/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [33/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [34/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [35/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [36/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [37/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [38/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [39/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [40/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [41/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [42/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [43/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [44/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [45/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [46/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [47/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [48/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [49/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [50/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [51/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [52/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [53/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [54/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [55/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [56/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [57/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [58/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [59/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [60/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [61/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [62/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [63/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [64/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [65/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [66/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [67/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [68/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [69/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [70/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [71/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [72/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [73/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [74/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [75/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [76/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [77/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [78/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [79/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [80/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [81/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [82/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [83/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [84/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [85/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [86/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [87/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [88/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [89/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [90/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [91/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [92/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [93/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [94/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [95/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [96/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [97/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [98/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [99/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [100/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Finished evaluation at 2018-02-13-15:15:05\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving dict for global step 1000: accuracy = 0.78898436, global_step = 1000, loss = 0.6734035\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Restoring parameters from s3://sagemaker-us-east-2-780175542751/sagemaker-tensorflow-py2-cpu-2018-02-13-15-09-28-445/checkpoints/model.ckpt-1000\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Assets added to graph.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:SavedModel written to: s3://sagemaker-us-east-2-780175542751/sagemaker-tensorflow-py2-cpu-2018-02-13-15-09-28-445/checkpoints/export/Servo/temp-1518534906/saved_model.pb\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:writing success training\u001b[0m\n",
      "\u001b[31m2018-02-13 15:15:08,107 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-02-13 15:15:08,165 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.us-east-2.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-02-13 15:15:08,226 INFO - tf_container.serve - Downloaded saved model at /opt/ml/model/export/Servo/1518534906/saved_model.pb\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "custom_estimator = TensorFlow(entry_point='custom_estimator.py',\n",
    "                               role=role,\n",
    "                               training_steps= 1000,                                  \n",
    "                               evaluation_steps= 100,\n",
    "                               hyperparameters={'learning_rate': 0.001},\n",
    "                               train_instance_count=1,\n",
    "                               train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "custom_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-tensorflow-py2-cpu-2018-02-13-15-09-28-445\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-tensorflow-py2-cpu-2018-02-13-15-09-28-445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "custom_predictor = custom_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "prediction_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "    filename=os.path.join('data/post_holdout.csv'), target_dtype=np.int, features_dtype=np.float32)\n",
    "\n",
    "data = prediction_set.data[0]\n",
    "tensor_proto = tf.make_tensor_proto(values=np.asarray(data), shape=[1, len(data)], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs': {'jobs': {'dtype': 'DT_INT64',\n",
       "   'int64Val': ['6'],\n",
       "   'tensorShape': {'dim': [{'size': '1'}]}}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_predictor.predict(tensor_proto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete endpoint (make sure to do this if just testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-tensorflow-py2-cpu-2018-02-13-15-09-28-445\n"
     ]
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(custom_predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
